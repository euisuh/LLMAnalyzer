{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de8efcc4-2c42-4b52-af56-54ce4f317be3",
   "metadata": {},
   "source": [
    "## Download HF dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83a33fff-d10c-47c0-856e-1826739697d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "n_per_dataset = 200\n",
    "df = pd.DataFrame(columns=['prompt_en', 'prompt_ar', 'response_en', 'response_ar', 'source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd050fdb-81da-4324-8089-d8cfb4359389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2045, 4)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_repo = 'akoksal/LongForm'\n",
    "dataset = load_dataset(dataset_repo, split='test')\n",
    "\n",
    "df_longForm = pd.DataFrame(dataset)\n",
    "df_longForm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "02001f25-0947-451b-aaba-4c42a32d5e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>source</th>\n",
       "      <th>subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyze the information presented in the text ...</td>\n",
       "      <td>Mueller’s proposed questions are presumably th...</td>\n",
       "      <td>C4</td>\n",
       "      <td>instruction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the aspects of Buddhism and it's scri...</td>\n",
       "      <td>What are the aspects of Buddhism and it's scri...</td>\n",
       "      <td>StackExchange</td>\n",
       "      <td>buddhism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Unable to conditionally test for presence of a...</td>\n",
       "      <td>The problem is, your vimrc file is executed be...</td>\n",
       "      <td>StackExchange</td>\n",
       "      <td>vi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is Por Macau?</td>\n",
       "      <td>Por Macau () is a political party in Macau, Ch...</td>\n",
       "      <td>Wikipedia</td>\n",
       "      <td>chatbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why are passengers requested to close their wi...</td>\n",
       "      <td>This is a personal experience rather than an a...</td>\n",
       "      <td>StackExchange</td>\n",
       "      <td>aviation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               input  \\\n",
       "0  Analyze the information presented in the text ...   \n",
       "1  What are the aspects of Buddhism and it's scri...   \n",
       "2  Unable to conditionally test for presence of a...   \n",
       "3                                 What is Por Macau?   \n",
       "4  Why are passengers requested to close their wi...   \n",
       "\n",
       "                                              output         source  \\\n",
       "0  Mueller’s proposed questions are presumably th...             C4   \n",
       "1  What are the aspects of Buddhism and it's scri...  StackExchange   \n",
       "2  The problem is, your vimrc file is executed be...  StackExchange   \n",
       "3  Por Macau () is a political party in Macau, Ch...      Wikipedia   \n",
       "4  This is a personal experience rather than an a...  StackExchange   \n",
       "\n",
       "        subset  \n",
       "0  instruction  \n",
       "1     buddhism  \n",
       "2           vi  \n",
       "3      chatbot  \n",
       "4     aviation  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_longForm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "103ef945-3f4c-452b-b6dc-189c3c191f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 5)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsampled_df = df_longForm[['input', 'output']].sample(n=n_per_dataset).reset_index(drop=True)\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame(\n",
    "    {'prompt_en': subsampled_df['input'].tolist(),\n",
    "     'prompt_ar': '',\n",
    "     'response_en': subsampled_df['output'].tolist(),\n",
    "     'response_ar': '',\n",
    "     'source': dataset_repo,\n",
    "    })], ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0aded5d1-b369-4d1a-8313-2ac45f64180f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9229, 3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_repo = 'mlabonne/alpagasus'\n",
    "dataset = load_dataset(dataset_repo, split='train')\n",
    "\n",
    "df_alpagasus = pd.DataFrame(dataset)\n",
    "df_alpagasus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ad393af-713e-40c0-8084-6d4839d53f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6706, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alpagasus = df_alpagasus[df_alpagasus['input'] == '']\n",
    "df_alpagasus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cee9243c-d05e-4273-97a5-4c677bd41e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instruction</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Give three tips for staying healthy.</td>\n",
       "      <td></td>\n",
       "      <td>1.Eat a balanced diet and make sure to include...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How can we reduce air pollution?</td>\n",
       "      <td></td>\n",
       "      <td>There are a number of ways to reduce air pollu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Generate a list of ten items a person might ne...</td>\n",
       "      <td></td>\n",
       "      <td>1. Tent\\n2. Sleeping bags\\n3. Flashlight\\n4. M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Discuss the causes of the Great Depression</td>\n",
       "      <td></td>\n",
       "      <td>The Great Depression was a severe global econo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Describe the function of a computer motherboard</td>\n",
       "      <td></td>\n",
       "      <td>A computer motherboard is the main circuit boa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         instruction input  \\\n",
       "0               Give three tips for staying healthy.         \n",
       "1                   How can we reduce air pollution?         \n",
       "2  Generate a list of ten items a person might ne...         \n",
       "3         Discuss the causes of the Great Depression         \n",
       "5    Describe the function of a computer motherboard         \n",
       "\n",
       "                                              output  \n",
       "0  1.Eat a balanced diet and make sure to include...  \n",
       "1  There are a number of ways to reduce air pollu...  \n",
       "2  1. Tent\\n2. Sleeping bags\\n3. Flashlight\\n4. M...  \n",
       "3  The Great Depression was a severe global econo...  \n",
       "5  A computer motherboard is the main circuit boa...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alpagasus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83c9516e-3a5c-4ead-aca2-7757111b2d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 5)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsampled_df = df_alpagasus[['instruction', 'output']].sample(n=n_per_dataset).reset_index(drop=True)\n",
    "\n",
    "df = pd.concat([df, pd.DataFrame(\n",
    "    {'prompt_en': subsampled_df['instruction'].tolist(),\n",
    "     'prompt_ar': '',\n",
    "     'response_en': subsampled_df['output'].tolist(),\n",
    "     'response_ar': '',\n",
    "     'source': dataset_repo,\n",
    "    })], ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cba8e788-f2b0-4b73-8476-a70a0559f524",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 104/104 [00:00<00:00, 441kB/s]\n",
      "Downloading data: 100%|██████████| 142k/142k [00:00<00:00, 296kB/s]\n",
      "Generating test split: 180 examples [00:00, 42445.31 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(180, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_repo = 'HuggingFaceH4/Koala-test-set'\n",
    "dataset = load_dataset(dataset_repo, split='test')\n",
    "\n",
    "df_koala = pd.DataFrame(dataset)\n",
    "df_koala.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdab1dd5-1781-41a9-a778-e7931b9d29ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>koala_0</td>\n",
       "      <td>Can you list the top 20 films or movies betwee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>koala_1</td>\n",
       "      <td>Take MLK speech \"I had a dream\" but turn it in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>koala_2</td>\n",
       "      <td>List the layers of the TCP/IP model and for ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>koala_3</td>\n",
       "      <td>Please proofread and polish the passage from a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>koala_4</td>\n",
       "      <td>Why can't bank use cash as capital as a buffer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt\n",
       "0  koala_0  Can you list the top 20 films or movies betwee...\n",
       "1  koala_1  Take MLK speech \"I had a dream\" but turn it in...\n",
       "2  koala_2  List the layers of the TCP/IP model and for ea...\n",
       "3  koala_3  Please proofread and polish the passage from a...\n",
       "4  koala_4  Why can't bank use cash as capital as a buffer..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_koala.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "29ef9a7f-6624-453b-822e-500bd1ce8829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(580, 5)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, pd.DataFrame(\n",
    "    {'prompt_en': df_koala['prompt'].tolist(),\n",
    "     'prompt_ar': '',\n",
    "     'response_en': '',\n",
    "     'response_ar': '',\n",
    "     'source': dataset_repo,\n",
    "    })], ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0974f42-c126-4bd4-a312-574c5daabe54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data:  52%|█████▏    | 41.9M/80.4M [00:15<00:04, 9.33MB/s]\n",
      "Downloading data:   0%|          | 0.00/80.4M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data:  13%|█▎        | 10.5M/80.4M [00:04<00:27, 2.56MB/s]\u001b[A\n",
      "Downloading data:  26%|██▌       | 21.0M/80.4M [00:04<00:12, 4.87MB/s]\u001b[A\n",
      "Downloading data:  39%|███▉      | 31.5M/80.4M [00:05<00:07, 6.76MB/s]\u001b[A\n",
      "Downloading data:  52%|█████▏    | 41.9M/80.4M [00:06<00:04, 8.35MB/s]\u001b[A\n",
      "Downloading data:  65%|██████▌   | 52.4M/80.4M [00:08<00:04, 6.49MB/s]\u001b[A\n",
      "Downloading data:  78%|███████▊  | 62.9M/80.4M [00:09<00:02, 7.82MB/s]\u001b[A\n",
      "Downloading data:  91%|█████████▏| 73.4M/80.4M [00:10<00:00, 8.79MB/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 80.4M/80.4M [00:11<00:00, 7.25MB/s]\u001b[A\n",
      "\n",
      "Generating train_sft split:   0%|          | 0/207865 [00:00<?, ? examples/s]\u001b[A\n",
      "Generating train_sft split:   3%|▎         | 7000/207865 [00:00<00:03, 61090.06 examples/s]\u001b[A\n",
      "Generating train_sft split:   7%|▋         | 15000/207865 [00:00<00:02, 66963.37 examples/s]\u001b[A\n",
      "Generating train_sft split:  11%|█         | 23000/207865 [00:00<00:02, 69604.51 examples/s]\u001b[A\n",
      "Generating train_sft split:  15%|█▌        | 32000/207865 [00:00<00:02, 73155.56 examples/s]\u001b[A\n",
      "Generating train_sft split:  19%|█▉        | 40000/207865 [00:00<00:02, 74359.36 examples/s]\u001b[A\n",
      "Generating train_sft split:  23%|██▎       | 48000/207865 [00:00<00:02, 73371.58 examples/s]\u001b[A\n",
      "Generating train_sft split:  28%|██▊       | 58000/207865 [00:00<00:02, 64496.92 examples/s]\u001b[A\n",
      "Generating train_sft split:  33%|███▎      | 68000/207865 [00:01<00:02, 61081.83 examples/s]\u001b[A\n",
      "Generating train_sft split:  37%|███▋      | 76289/207865 [00:01<00:02, 64098.39 examples/s]\u001b[A\n",
      "Generating train_sft split:  41%|████      | 85289/207865 [00:01<00:01, 68388.29 examples/s]\u001b[A\n",
      "Generating train_sft split:  45%|████▌     | 94289/207865 [00:01<00:01, 70640.00 examples/s]\u001b[A\n",
      "Generating train_sft split:  50%|████▉     | 103289/207865 [00:01<00:01, 74610.57 examples/s]\u001b[A\n",
      "Generating train_sft split:  54%|█████▎    | 111289/207865 [00:01<00:01, 73334.61 examples/s]\u001b[A\n",
      "Generating train_sft split:  57%|█████▋    | 119289/207865 [00:01<00:01, 73024.66 examples/s]\u001b[A\n",
      "Generating train_sft split:  61%|██████    | 127289/207865 [00:01<00:01, 72069.02 examples/s]\u001b[A\n",
      "Generating train_sft split:  66%|██████▌   | 136289/207865 [00:01<00:00, 73305.67 examples/s]\u001b[A\n",
      "Generating train_sft split:  71%|███████▏  | 148577/207865 [00:02<00:00, 74598.71 examples/s]\u001b[A\n",
      "Generating train_sft split:  77%|███████▋  | 160577/207865 [00:02<00:00, 73619.04 examples/s]\u001b[A\n",
      "Generating train_sft split:  81%|████████  | 168577/207865 [00:02<00:00, 72925.57 examples/s]\u001b[A\n",
      "Generating train_sft split:  85%|████████▍ | 176577/207865 [00:02<00:00, 72209.67 examples/s]\u001b[A\n",
      "Generating train_sft split:  90%|████████▉ | 186577/207865 [00:02<00:00, 64227.35 examples/s]\u001b[A\n",
      "Generating train_sft split:  95%|█████████▍| 196577/207865 [00:02<00:00, 57251.62 examples/s]\u001b[A\n",
      "Generating train_sft split: 100%|██████████| 207865/207865 [00:03<00:00, 68022.06 examples/s]\u001b[A\n",
      "\n",
      "Generating test_sft split:   0%|          | 0/23110 [00:00<?, ? examples/s]\u001b[A\n",
      "Generating test_sft split:  39%|███▉      | 9000/23110 [00:00<00:00, 73161.85 examples/s]\u001b[A\n",
      "Generating test_sft split: 100%|██████████| 23110/23110 [00:00<00:00, 72795.41 examples/s]\u001b[A\n",
      "\n",
      "Generating train_gen split:   0%|          | 0/256032 [00:00<?, ? examples/s]\u001b[A\n",
      "Generating train_gen split:   4%|▍         | 10000/256032 [00:00<00:02, 97471.68 examples/s]\u001b[A\n",
      "Generating train_gen split:   8%|▊         | 20000/256032 [00:00<00:02, 93039.65 examples/s]\u001b[A\n",
      "Generating train_gen split:  12%|█▏        | 30000/256032 [00:00<00:02, 92814.51 examples/s]\u001b[A\n",
      "Generating train_gen split:  16%|█▌        | 40000/256032 [00:00<00:02, 93464.11 examples/s]\u001b[A\n",
      "Generating train_gen split:  20%|█▉        | 51000/256032 [00:00<00:02, 97095.32 examples/s]\u001b[A\n",
      "Generating train_gen split:  24%|██▍       | 62000/256032 [00:00<00:01, 100184.34 examples/s]\u001b[A\n",
      "Generating train_gen split:  30%|███       | 78000/256032 [00:00<00:01, 98430.33 examples/s] \u001b[A\n",
      "Generating train_gen split:  36%|███▌      | 91344/256032 [00:00<00:01, 91331.93 examples/s]\u001b[A\n",
      "Generating train_gen split:  40%|███▉      | 102344/256032 [00:01<00:01, 91684.24 examples/s]\u001b[A\n",
      "Generating train_gen split:  44%|████▍     | 112344/256032 [00:01<00:01, 89172.81 examples/s]\u001b[A\n",
      "Generating train_gen split:  48%|████▊     | 123344/256032 [00:01<00:01, 90808.88 examples/s]\u001b[A\n",
      "Generating train_gen split:  54%|█████▍    | 138344/256032 [00:01<00:01, 91359.74 examples/s]\u001b[A\n",
      "Generating train_gen split:  58%|█████▊    | 148344/256032 [00:01<00:01, 92078.10 examples/s]\u001b[A\n",
      "Generating train_gen split:  62%|██████▏   | 158344/256032 [00:01<00:01, 92357.49 examples/s]\u001b[A\n",
      "Generating train_gen split:  66%|██████▌   | 168344/256032 [00:01<00:00, 90430.43 examples/s]\u001b[A\n",
      "Generating train_gen split:  69%|██████▉   | 177688/256032 [00:01<00:00, 88163.04 examples/s]\u001b[A\n",
      "Generating train_gen split:  73%|███████▎  | 186688/256032 [00:02<00:00, 85644.26 examples/s]\u001b[A\n",
      "Generating train_gen split:  76%|███████▋  | 195688/256032 [00:02<00:00, 84733.00 examples/s]\u001b[A\n",
      "Generating train_gen split:  80%|████████  | 205688/256032 [00:02<00:00, 85008.59 examples/s]\u001b[A\n",
      "Generating train_gen split:  85%|████████▌ | 218688/256032 [00:02<00:00, 76751.61 examples/s]\u001b[A\n",
      "Generating train_gen split:  90%|████████▉ | 229688/256032 [00:02<00:00, 82314.54 examples/s]\u001b[A\n",
      "Generating train_gen split:  94%|█████████▍| 240688/256032 [00:02<00:00, 85569.93 examples/s]\u001b[A\n",
      "Generating train_gen split: 100%|██████████| 256032/256032 [00:02<00:00, 89618.13 examples/s]\u001b[A\n",
      "\n",
      "Generating test_gen split:   0%|          | 0/28304 [00:00<?, ? examples/s]\u001b[A\n",
      "Generating test_gen split:  39%|███▉      | 11000/28304 [00:00<00:00, 100198.59 examples/s]\u001b[A\n",
      "Generating test_gen split: 100%|██████████| 28304/28304 [00:00<00:00, 90591.88 examples/s] \u001b[A\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23110, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_repo = 'HuggingFaceH4/ultrachat_200k'\n",
    "dataset = load_dataset(dataset_repo, split='test_sft')\n",
    "\n",
    "df_ultra = pd.DataFrame(dataset)\n",
    "df_ultra.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33dbe299-7d27-4c12-9b09-6d078813b5a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does the author propose to fix the problem...</td>\n",
       "      <td>9fb649a870769f4881c647d20d178656f67fc881b2dc0b...</td>\n",
       "      <td>[{'content': 'How does the author propose to f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rice tolerance to suboptimal low temperatures ...</td>\n",
       "      <td>26afb4f9bffc82fbbfdcaa8f0eec0833780e411799dcee...</td>\n",
       "      <td>[{'content': 'Rice tolerance to suboptimal low...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Write a free verse poem about the power of the...</td>\n",
       "      <td>3ab0d0c24777248cbc4aa33971d34e8de9393db1ea0cc1...</td>\n",
       "      <td>[{'content': 'Write a free verse poem about th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compose a speech about the need for more affor...</td>\n",
       "      <td>5dac3c072ba477af9ed0c71a31a806f307d7ea839a7977...</td>\n",
       "      <td>[{'content': 'Compose a speech about the need ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Write a historical fiction story that is set d...</td>\n",
       "      <td>b750ea229635aa6683e0018abd17f92804376c1b0c474d...</td>\n",
       "      <td>[{'content': 'Write a historical fiction story...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  How does the author propose to fix the problem...   \n",
       "1  Rice tolerance to suboptimal low temperatures ...   \n",
       "2  Write a free verse poem about the power of the...   \n",
       "3  Compose a speech about the need for more affor...   \n",
       "4  Write a historical fiction story that is set d...   \n",
       "\n",
       "                                           prompt_id  \\\n",
       "0  9fb649a870769f4881c647d20d178656f67fc881b2dc0b...   \n",
       "1  26afb4f9bffc82fbbfdcaa8f0eec0833780e411799dcee...   \n",
       "2  3ab0d0c24777248cbc4aa33971d34e8de9393db1ea0cc1...   \n",
       "3  5dac3c072ba477af9ed0c71a31a806f307d7ea839a7977...   \n",
       "4  b750ea229635aa6683e0018abd17f92804376c1b0c474d...   \n",
       "\n",
       "                                            messages  \n",
       "0  [{'content': 'How does the author propose to f...  \n",
       "1  [{'content': 'Rice tolerance to suboptimal low...  \n",
       "2  [{'content': 'Write a free verse poem about th...  \n",
       "3  [{'content': 'Compose a speech about the need ...  \n",
       "4  [{'content': 'Write a historical fiction story...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ultra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4b1cd0e0-7f16-476a-b64f-e9296637baf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'The author proposes to fix the problem of science alienation in our educational system by splitting K-12 science education into two tracks, for majors and nonmajors. Those who want to specialize in science could take math and complex chemistry, while nonmajors would focus on science of the everyday – things like kitchen chemistry and CSI-style crime investigations. All high school students should take four years of science, and the tracking system could build on existing science electives. The goal is to teach every student a solid understanding and appreciation of science, one that will remain useful to both themselves and society throughout their lives.',\n",
       " 'role': 'assistant'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ultra.messages.iloc[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e5aff710-356e-48f7-94dc-8668de3061b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 200)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsampled_df = df_ultra[['prompt', 'messages']].sample(n=n_per_dataset).reset_index(drop=True)\n",
    "collect_prompt = []\n",
    "collect_response = []\n",
    "\n",
    "for i in range(subsampled_df.shape[0]):\n",
    "    messages = subsampled_df.messages.iloc[i]\n",
    "    current_role = 'user'\n",
    "\n",
    "    collect_prompt_sub = []\n",
    "    collect_response_sub = []\n",
    "    \n",
    "    for message in messages:\n",
    "        role = message['role']\n",
    "        content = message['content']\n",
    "        if role != current_role:\n",
    "            break\n",
    "        \n",
    "        if current_role == 'user':\n",
    "            collect_prompt_sub.append(content)\n",
    "            current_role = 'assistant'\n",
    "        else:\n",
    "            collect_response_sub.append(content)\n",
    "            current_role = 'user'\n",
    "\n",
    "    if len(collect_prompt_sub) != 0:\n",
    "        collect_prompt.append(collect_prompt_sub)\n",
    "        collect_response.append(collect_response_sub)\n",
    "\n",
    "len(collect_prompt), len(collect_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7e50239e-fc80-43ee-8861-60e49f11cdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(780, 5)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, pd.DataFrame(\n",
    "    {'prompt_en': collect_prompt,\n",
    "     'prompt_ar': '',\n",
    "     'response_en': collect_response,\n",
    "     'response_ar': '',\n",
    "     'source': dataset_repo,\n",
    "    })], ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "81e64d4b-dfeb-4be5-9628-bef3564898f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading readme: 100%|██████████| 1.49k/1.49k [00:00<00:00, 4.85MB/s]\n",
      "\n",
      "Downloading data:   0%|          | 0.00/30.1k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 30.1k/30.1k [00:01<00:00, 21.3kB/s]\u001b[A\n",
      "\n",
      "Generating train split: 80 examples [00:00, 13729.87 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80, 4)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_repo = 'HuggingFaceH4/mt_bench_prompts'\n",
    "dataset = load_dataset(dataset_repo, split='train')\n",
    "\n",
    "df_mt = pd.DataFrame(dataset)\n",
    "df_mt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "24578987-2005-44b5-9a76-c574a65b40dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>prompt</th>\n",
       "      <th>reference</th>\n",
       "      <th>prompt_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>writing</td>\n",
       "      <td>[Compose an engaging travel blog post about a ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>44067482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>writing</td>\n",
       "      <td>[Draft a professional email seeking your super...</td>\n",
       "      <td>[]</td>\n",
       "      <td>49723273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>writing</td>\n",
       "      <td>[Imagine you are writing a blog post comparing...</td>\n",
       "      <td>[]</td>\n",
       "      <td>72595869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>writing</td>\n",
       "      <td>[Write a persuasive email to convince your int...</td>\n",
       "      <td>[]</td>\n",
       "      <td>9147946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>writing</td>\n",
       "      <td>[Describe a vivid and unique character, using ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>3075696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                             prompt reference  \\\n",
       "0  writing  [Compose an engaging travel blog post about a ...        []   \n",
       "1  writing  [Draft a professional email seeking your super...        []   \n",
       "2  writing  [Imagine you are writing a blog post comparing...        []   \n",
       "3  writing  [Write a persuasive email to convince your int...        []   \n",
       "4  writing  [Describe a vivid and unique character, using ...        []   \n",
       "\n",
       "   prompt_id  \n",
       "0   44067482  \n",
       "1   49723273  \n",
       "2   72595869  \n",
       "3    9147946  \n",
       "4    3075696  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "455077b4-0890-4ae2-b372-afeddc7a94c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(860, 5)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, pd.DataFrame(\n",
    "    {'prompt_en': df_mt['prompt'].tolist(),\n",
    "     'prompt_ar': '',\n",
    "     'response_en': '',\n",
    "     'response_ar': '',\n",
    "     'source': dataset_repo,\n",
    "    })], ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7338855e-2c0f-49ea-b718-75decfad393c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading readme: 100%|██████████| 549/549 [00:00<00:00, 3.01MB/s]\n",
      "\n",
      "Downloading data:   0%|          | 0.00/7.11M [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 7.11M/7.11M [00:05<00:00, 1.23MB/s]\u001b[A\n",
      "\n",
      "Downloading data:   0%|          | 0.00/803k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|██████████| 803k/803k [00:01<00:00, 522kB/s]\u001b[A\n",
      "\n",
      "Generating train split: 100%|██████████| 9418/9418 [00:00<00:00, 322989.63 examples/s]\n",
      "\n",
      "Generating test split: 100%|██████████| 1047/1047 [00:00<00:00, 148009.31 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1047, 4)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset_repo = 'reciprocate/alpaca-eval'\n",
    "dataset = load_dataset(dataset_repo, split='test')\n",
    "\n",
    "df_alpaca = pd.DataFrame(dataset)\n",
    "df_alpaca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "de890fac-859a-4027-8db0-70a43dd4022d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>selected</th>\n",
       "      <th>rejected</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USER: You are given a paper citation, convert ...</td>\n",
       "      <td>Vaswani, Ashish, et al. “Attention Is All You ...</td>\n",
       "      <td>Vaswani, Ashish, et al. \"Attention Is All You ...</td>\n",
       "      <td>selfinstruct/alpaca_eval_gpt4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USER: what is needed for self-sufficient livin...</td>\n",
       "      <td>In order to create self-sufficient living spac...</td>\n",
       "      <td>In order to create self-sufficient living spac...</td>\n",
       "      <td>koala/alpaca_eval_gpt4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USER: can you please create a python script th...</td>\n",
       "      <td>Here's a Python script that calculates the der...</td>\n",
       "      <td># This program will calculate the derivative o...</td>\n",
       "      <td>oasst/alpaca_eval_gpt4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USER: Find sentences from reliable sources suc...</td>\n",
       "      <td>Here are two sentences containing the exact ph...</td>\n",
       "      <td>\"There are great options for people who are lo...</td>\n",
       "      <td>selfinstruct/alpaca_eval_gpt4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USER: What is kevlar made out of? ASSISTANT:</td>\n",
       "      <td>Kevlar is a synthetic fiber that is made from ...</td>\n",
       "      <td>Kevlar is made out of poly-paraphenylene terep...</td>\n",
       "      <td>helpful_base/alpaca_eval_gpt4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0  USER: You are given a paper citation, convert ...   \n",
       "1  USER: what is needed for self-sufficient livin...   \n",
       "2  USER: can you please create a python script th...   \n",
       "3  USER: Find sentences from reliable sources suc...   \n",
       "4      USER: What is kevlar made out of? ASSISTANT:    \n",
       "\n",
       "                                            selected  \\\n",
       "0  Vaswani, Ashish, et al. “Attention Is All You ...   \n",
       "1  In order to create self-sufficient living spac...   \n",
       "2  Here's a Python script that calculates the der...   \n",
       "3  Here are two sentences containing the exact ph...   \n",
       "4  Kevlar is a synthetic fiber that is made from ...   \n",
       "\n",
       "                                            rejected  \\\n",
       "0  Vaswani, Ashish, et al. \"Attention Is All You ...   \n",
       "1  In order to create self-sufficient living spac...   \n",
       "2  # This program will calculate the derivative o...   \n",
       "3  \"There are great options for people who are lo...   \n",
       "4  Kevlar is made out of poly-paraphenylene terep...   \n",
       "\n",
       "                          source  \n",
       "0  selfinstruct/alpaca_eval_gpt4  \n",
       "1         koala/alpaca_eval_gpt4  \n",
       "2         oasst/alpaca_eval_gpt4  \n",
       "3  selfinstruct/alpaca_eval_gpt4  \n",
       "4  helpful_base/alpaca_eval_gpt4  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_alpaca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "282b655d-c780-4f87-bfca-11f7793bfe72",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampled_df = df_alpaca[['prompt', 'selected']].sample(n=n_per_dataset).reset_index(drop=True)\n",
    "\n",
    "for i in range(subsampled_df.shape[0]):\n",
    "    if subsampled_df.prompt.iloc[i][:6] != 'USER: ':\n",
    "        print('Uneven prompt pattern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "51b9b330-1d7d-4b9c-aef8-115549379591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1907, 5)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df, pd.DataFrame(\n",
    "    {'prompt_en': [i[6:] for i in subsampled_df['prompt'].tolist()],\n",
    "     'prompt_ar': '',\n",
    "     'response_en': df_alpaca['selected'].tolist(),\n",
    "     'response_ar': '',\n",
    "     'source': dataset_repo,\n",
    "    })], ignore_index=True)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a431a9-d335-48de-ba40-0c13fb64f40c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
